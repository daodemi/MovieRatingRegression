{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n",
      "Requirement already satisfied: python-dotenv in /anaconda3/lib/python3.7/site-packages (0.10.1)\n",
      "\u001b[31mtwisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import http.client\n",
    "import json\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRAPE MOVIE TITLES HASH FROM TOP 100 BEST FILMS 2014-2018\n",
    "\n",
    "url_18_50 = 'https://www.imdb.com/search/title?title_type=feature&year=2018-01-01,2018-12-31&sort=num_votes,desc'\n",
    "url_17_50 = 'https://www.imdb.com/search/title?title_type=feature&year=2017-01-01,2017-12-31&sort=num_votes,desc'\n",
    "url_16_50 = 'https://www.imdb.com/search/title?title_type=feature&year=2016-01-01,2016-12-31&sort=num_votes,desc'\n",
    "url_15_50 = 'https://www.imdb.com/search/title?title_type=feature&year=2015-01-01,2015-12-31&sort=num_votes,desc'\n",
    "url_14_50 = 'https://www.imdb.com/search/title?title_type=feature&year=2014-01-01,2014-12-31&sort=num_votes,desc'\n",
    "url_18_100 = 'https://www.imdb.com/search/title?title_type=feature&year=2018-01-01,2018-12-31&sort=num_votes,desc&start=51&ref_=adv_nxt'\n",
    "url_17_100 = 'https://www.imdb.com/search/title?title_type=feature&year=2017-01-01,2017-12-31&sort=num_votes,desc&start=51&ref_=adv_nxt'\n",
    "url_16_100 = 'https://www.imdb.com/search/title?title_type=feature&year=2016-01-01,2016-12-31&sort=num_votes,desc&start=51&ref_=adv_nxt'\n",
    "url_15_100 = 'https://www.imdb.com/search/title?title_type=feature&year=2015-01-01,2015-12-31&sort=num_votes,desc&start=51&ref_=adv_nxt'\n",
    "url_14_100 = 'https://www.imdb.com/search/title?title_type=feature&year=2014-01-01,2014-12-31&sort=num_votes,desc&start=51&ref_=adv_nxt'\n",
    "\n",
    "\n",
    "urls = [url_18_50, url_18_100, url_17_50, url_17_100, url_16_50, url_16_100, url_15_50, url_15_100, url_14_50, url_14_100]\n",
    "hashes = []\n",
    "\n",
    "for url in urls:\n",
    "    links = []\n",
    "    hash = []\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    for link in soup.find_all('a'):\n",
    "        links.append(link.get('href'))\n",
    "    links = links[90:]\n",
    "    for link in links:\n",
    "        if \"/title/\" in link:\n",
    "            hash.append(link[7:16])\n",
    "            hash = list(set(hash))\n",
    "    hashes.append(hash)\n",
    "    \n",
    "hashes = list(chain.from_iterable(hashes)) # unnest list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash = 'tt1825683'\n",
    "url = 'https://www.imdb.com/title/tt4154796/?ref_=ttls_li_tt'\n",
    "response = requests.get(url)   \n",
    "page = response.text\n",
    "soup = BeautifulSoup(page, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRating(soup):\n",
    "    rating = soup.find(itemprop=\"ratingValue\").get_text()\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.imdb.com/title/{}/?ref_=adv_li_tt'.format(hash)\n",
    "response = requests.get(url)   \n",
    "page = response.text\n",
    "souptest = BeautifulSoup(page, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTitle(soup):\n",
    "    try:\n",
    "        a = soup.find('h1')\n",
    "        b = str(a)\n",
    "        c = re.split('>|<', b)\n",
    "        title = c[2]\n",
    "        title = title.replace(u'\\xa0', u'')\n",
    "        return title\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://pro.imdb.com/title/{}/?ref_=instant_tt_1&q=avengers%20infi'.format(hash)\n",
    "driver.get(url)\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBudget(soup):\n",
    "    try:\n",
    "        budget = soup.find(class_=\"a-column a-span5 a-text-right a-span-last\").getText()\n",
    "        budget = budget.split()\n",
    "        return budget\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://pro.imdb.com/title/{}/filmmakers\".format(hash)\n",
    "filmmakers = soup.find_all(class_ = \"additional_info\")\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getDirectors(filmmakers):\n",
    "    try:\n",
    "        numDirectors = str(filmmakers[0])\n",
    "        numDirectors = numDirectors[numDirectors.find(\"(\")+1:numDirectors.find(\")\")]\n",
    "        return numDirectors\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def getWriters(filmmakers):\n",
    "    try:\n",
    "        numWriters = str(filmmakers[1])\n",
    "        numWriters = numWriters[numWriters.find(\"(\")+1:numWriters.find(\")\")]\n",
    "        return numWriters\n",
    "    except: \n",
    "        return None\n",
    "    \n",
    "def getProducers(filmmakers):\n",
    "    try:\n",
    "        numProducers = str(filmmakers[2])\n",
    "        numProducers = numProducers[numProducers.find(\"(\")+1:numProducers.find(\")\")]\n",
    "        return numProducers\n",
    "    except: \n",
    "        return None\n",
    "    \n",
    "def getProductionManagers(filmmakers):\n",
    "    try:\n",
    "        numProductionManagers = str(filmmakers[12])\n",
    "        numProductionManagers = numProductionManagers[numProductionManagers.find(\"(\")+1:numProductionManagers.find(\")\")]\n",
    "        return numProductionManagers\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def getStunts(filmmakers):\n",
    "    try:\n",
    "        numStunts = str(filmmakers[18])\n",
    "        numStunts = numStunts[numStunts.find(\"(\")+1:numStunts.find(\")\")]\n",
    "        return numStunts\n",
    "    except:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://pro.imdb.com/title/{}/cast\".format(hash)\n",
    "filmmakers = soup.find_all(class_ = \"additional_info\")\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCast(soup):\n",
    "    try:\n",
    "        cast = soup.find(class_=\"a-size-mini a-color-secondary tab_subheading\")\n",
    "        cast = str(cast)\n",
    "        numCast = cast[cast.find('> ')+1:cast.find(\" cast\")].split()\n",
    "        return numCast\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def getStarRating(soup):\n",
    "    try:\n",
    "        rating = soup.find(class_ = \"a-size-mini a-color-secondary tab_subheading\")\n",
    "        rating = str(rating)\n",
    "        starRating = rating[rating.find('> ')+1:rating.find(\" cast\")].split()\n",
    "        starRating = starRating[0]\n",
    "        return starRating\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://pro.imdb.com/title/{}/companycredits\".format(hash)\n",
    "driver.get(url)\n",
    "soup3 = BeautifulSoup(driver.page_source, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProductionCompanies(soup):\n",
    "    try:\n",
    "        numProductionCompanies = str(companies[0])\n",
    "        numProductionCompanies = numProductionCompanies[numProductionCompanies.find(\"(\")+1:numProductionCompanies.find(\")\")]\n",
    "        return numProductionCompanies\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def getDistributors(soup):\n",
    "    try:\n",
    "        numDistributors = str(companies[1])\n",
    "        numDistributors = numDistributors[numDistributors.find(\"(\")+1:numDistributors.find(\")\")]\n",
    "        return numDistributors\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dict = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hash in hashes:\n",
    "    url = 'https://www.imdb.com/title/{}/?ref_=adv_li_tt'.format(hash)\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    time.sleep(3+2*random.random())\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    movies_dict[hash].append(getTitle(soup))\n",
    "    time.sleep(8+2*random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGIN IMDB PRO WITH SELENIUM\n",
    "\n",
    "chromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "driver.get(\"https://pro.imdb.com/signup/index.html?u=https%3A%2F%2Fpro.imdb.com%2F\")\n",
    "\n",
    "time.sleep(5+2*random.random())\n",
    "driver.find_element_by_id(\"imdb_pro_login_popover\").click()\n",
    "\n",
    "time.sleep(5+2*random.random())\n",
    "\n",
    "driver.find_element_by_id(\"login_with_amazon\").click()\n",
    "\n",
    "time.sleep(5+2*random.random())\n",
    "\n",
    "EMAIL = os.environ.get('USERNAME')\n",
    "PASSWORD = os.environ.get('PASSWORD')\n",
    "\n",
    "email = driver.find_element_by_id(\"ap_email\")\n",
    "email.send_keys(EMAIL)\n",
    "email.send_keys(Keys.TAB)\n",
    "\n",
    "password = driver.find_element_by_id(\"ap_password\")\n",
    "password.send_keys(PASSWORD)\n",
    "password.send_keys(Keys.TAB)\n",
    "\n",
    "driver.find_element_by_id(\"ap_remember_me_checkbox\").click()\n",
    "driver.find_element_by_id(\"signInSubmit\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hash in hashes:\n",
    "    url = \"https://pro.imdb.com/title/{}/cast\".format(hash)\n",
    "    driver.get(url)\n",
    "    soup1 = BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "    movies_dict[hash].append(getCast(soup1))\n",
    "    movies_dict[hash].append(getStarRating(soup1))\n",
    "\n",
    "    time.sleep(.5+2*random.random())\n",
    "    \n",
    "    url = \"https://pro.imdb.com/title/{}/filmmakers\".format(hash)\n",
    "    driver.get(url)\n",
    "    soup2 = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    \n",
    "    filmmakers = soup2.find_all(class_ = \"additional_info\")\n",
    "    movies_dict[hash].append(getDirectors(filmmakers))\n",
    "    movies_dict[hash].append(getWriters(filmmakers))\n",
    "    movies_dict[hash].append(getProducers(filmmakers))    \n",
    "    movies_dict[hash].append(getProductionManagers(filmmakers))\n",
    "    movies_dict[hash].append(getStunts(filmmakers))\n",
    "\n",
    "    time.sleep(.5+2*random.random())\n",
    "    \n",
    "    url = \"https://pro.imdb.com/title/{}/companycredits\".format(hash)\n",
    "    driver.get(url)\n",
    "    soup3 = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    \n",
    "    companies = soup3.find_all(class_ = \"additional_info\")\n",
    "    movies_dict[hash].append(getProductionCompanies(soup3))\n",
    "    movies_dict[hash].append(getDistributors(soup3))\n",
    "    \n",
    "    time.sleep(.5+2*random.random())\n",
    "    \n",
    "    url = 'https://pro.imdb.com/title/{}/?ref_=instant_tt_1&q=avengers%20infi'.format(hash)\n",
    "    driver.get(url)\n",
    "    soup4 = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    \n",
    "    movies_dict[hash].append(getDistributors(soup))\n",
    "    \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_dict = defaultdict(list)\n",
    "\n",
    "for hash in hashes: \n",
    "    url = 'https://pro.imdb.com/title/{}/?ref_=instant_tt_1&q=avengers%20infi'.format(hash)\n",
    "    driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    budget_dict[hash].append(getBudget(soup))\n",
    "    time.sleep(.5+2*random.random())\n",
    "    \n",
    "budget_dict_df = pd.DataFrame.from_dict(budget_dict, orient = 'index')\n",
    "budget_dict_df.to_csv(\"budget_dict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOVIE DATABASE API\n",
    "\n",
    "for hash in hashes:\n",
    "    conn = http.client.HTTPSConnection(\"api.themoviedb.org\")\n",
    "    payload = \"{}\"\n",
    "    conn.request(\"GET\", \"/3/movie/{}?language=en-US&api_key=400430c5c9e81ffd2c06b5d25d7c09d1\".format(hash), payload)\n",
    "    res = conn.getresponse()\n",
    "    data = res.read()\n",
    "    movie = json.loads(data.decode(\"utf-8\"))\n",
    "    genre_dict = movie['genres']\n",
    "    genres = []\n",
    "\n",
    "    for key in genre_dict:\n",
    "        genres.append(key['name'])\n",
    "    \n",
    "    movies_dict1[hash].append(genres)\n",
    "    movies_dict1[hash].append(movie['runtime'])\n",
    "    movies_dict1[hash].append(movie['release_date'])\n",
    "    \n",
    "    time.sleep(4+2*random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hash in hashes:\n",
    "    url = 'https://www.imdb.com/title/{}/?ref_=ttls_li_tt'.format(hash)\n",
    "    response = requests.get(url)   \n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    movies_dict5[hash].append(getRating(soup))\n",
    "\n",
    "    time.sleep(4+2*random.random())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(movies_dict, orient = 'index')\n",
    "df.to_csv(\"movies_df1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame.from_dict(movies_dict1, orient = 'index')\n",
    "df1.to_csv(\"movies_df2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame.from_dict(log3, orient = 'index')\n",
    "df3.to_csv(\"movies_df3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame.from_dict(log3, orient = 'index')\n",
    "df4.to_csv(\"movies_df4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping data for recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_list = ['tt3513498', 'tt2386490', 'tt4154796']\n",
    "recs = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = defaultdict(list)\n",
    "\n",
    "for hash in recs_list:\n",
    "    conn = http.client.HTTPSConnection(\"api.themoviedb.org\")\n",
    "    payload = \"{}\"\n",
    "    conn.request(\"GET\", \"/3/movie/{}?language=en-US&api_key=400430c5c9e81ffd2c06b5d25d7c09d1\".format(hash), payload)\n",
    "    res = conn.getresponse()\n",
    "    data = res.read()\n",
    "    movie = json.loads(data.decode(\"utf-8\"))\n",
    "    genre_dict = movie['genres']\n",
    "    genres = []\n",
    "\n",
    "    for key in genre_dict:\n",
    "        genres.append(key['name'])\n",
    "    \n",
    "    time.sleep(.5+2*random.random())\n",
    "    \n",
    "    recs[hash].append(genres)\n",
    "    recs[hash].append(movie['runtime'])\n",
    "    recs[hash].append(movie['release_date'])\n",
    "\n",
    "    time.sleep(4+2*random.random())\n",
    "    \n",
    "chromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "driver.get(\"https://pro.imdb.com/signup/index.html?u=https%3A%2F%2Fpro.imdb.com%2F\")\n",
    "\n",
    "time.sleep(5+2*random.random())\n",
    "driver.find_element_by_id(\"imdb_pro_login_popover\").click()\n",
    "\n",
    "time.sleep(5+2*random.random())\n",
    "\n",
    "driver.find_element_by_id(\"login_with_amazon\").click()\n",
    "\n",
    "time.sleep(5+2*random.random())\n",
    "\n",
    "EMAIL = os.environ.get('USERNAME')\n",
    "PASSWORD = os.environ.get('PASSWORD')\n",
    "\n",
    "email = driver.find_element_by_id(\"ap_email\")\n",
    "email.send_keys(EMAIL)\n",
    "email.send_keys(Keys.TAB)\n",
    "\n",
    "password = driver.find_element_by_id(\"ap_password\")\n",
    "password.send_keys(PASSWORD)\n",
    "password.send_keys(Keys.TAB)\n",
    "\n",
    "driver.find_element_by_id(\"ap_remember_me_checkbox\").click()\n",
    "driver.find_element_by_id(\"signInSubmit\").click()  \n",
    "\n",
    "for hash in recs_list:\n",
    "    url = \"https://pro.imdb.com/title/{}/cast\".format(hash)\n",
    "    driver.get(url)\n",
    "    soup1 = BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "    recs[hash].append(getCast(soup1))\n",
    "\n",
    "    time.sleep(.5+2*random.random())\n",
    "    \n",
    "    url = \"https://pro.imdb.com/title/{}/filmmakers\".format(hash)\n",
    "    driver.get(url)\n",
    "    soup2 = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    \n",
    "    filmmakers = soup2.find_all(class_ = \"additional_info\")\n",
    "    recs[hash].append(getDirectors(filmmakers))\n",
    "    recs[hash].append(getWriters(filmmakers))\n",
    "    recs[hash].append(getProducers(filmmakers))    \n",
    "    recs[hash].append(getProductionManagers(filmmakers))\n",
    "    recs[hash].append(getStunts(filmmakers))\n",
    "\n",
    "    time.sleep(.5+2*random.random())\n",
    "    \n",
    "    url = \"https://pro.imdb.com/title/{}/companycredits\".format(hash)\n",
    "    driver.get(url)\n",
    "    soup3 = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    \n",
    "    companies = soup3.find_all(class_ = \"additional_info\")\n",
    "    recs[hash].append(getProductionCompanies(soup3))\n",
    "    recs[hash].append(getDistributors(soup3))\n",
    "    \n",
    "    time.sleep(.5+2*random.random())\n",
    "\n",
    "    \n",
    "    url = 'https://pro.imdb.com/title/{}/?ref_=instant_tt_1&q=avengers%20infi'.format(hash)\n",
    "    driver.get(url)\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    recs[hash].append(getBudget(soup))\n",
    "    time.sleep(.5+2*random.random())\n",
    "  \n",
    "    \n",
    "driver.close()\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = defaultdict(list,\n",
    "            {'tt3513498': [['Action','Adventure','Animation','Comedy','Family','Science Fiction','Fantasy'],\n",
    "              '106',\n",
    "              '2019-01-26',\n",
    "              '43',\n",
    "              '1',\n",
    "              '6',\n",
    "              '20',\n",
    "              '19',\n",
    "              '27',\n",
    "              '10',\n",
    "              '16',\n",
    "              '65000000'], #budget for prequel was used \n",
    "             'tt2386490': [['Animation', 'Family', 'Adventure'],\n",
    "              '104',\n",
    "              '2019-01-03',\n",
    "              '13',\n",
    "              '1',\n",
    "              '2',\n",
    "              '8',\n",
    "              '6',\n",
    "              '0',\n",
    "              '2',\n",
    "              '30',\n",
    "              '129000000'],\n",
    "             'tt4154796': [['Adventure', 'Science Fiction', 'Action'],\n",
    "              '180',\n",
    "              '2019-04-24',\n",
    "              '84',\n",
    "              '2',\n",
    "              '5',\n",
    "              '8',\n",
    "              '13',\n",
    "              '114',\n",
    "              '1',\n",
    "              '23',\n",
    "              '400000000']}) #budget for prequel was used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(recs, orient = 'index')\n",
    "df.to_csv(\"recs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
